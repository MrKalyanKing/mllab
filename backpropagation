import numpy
import matplotlib.pyplot as plt

# ----------------------------------------------------------------------------
# 1. Helper Functions
# ----------------------------------------------------------------------------

def sigmoid(sop):
    """Sigmoid activation function."""
    return 1.0 / (1 + numpy.exp(-sop))

def error(predicted, target):
    """Squared error between prediction and target."""
    return numpy.power(predicted - target, 2)

def error_predicted_deriv(predicted, target):
    """Derivative of error with respect to predicted value."""
    return 2 * (predicted - target)

def sigmoid_sop_deriv(sop):
    """Derivative of sigmoid with respect to its input (sop)."""
    s = sigmoid(sop)
    return s * (1.0 - s)

def sop_w_deriv(x):
    """Derivative of weighted sum (sop) with respect to weight."""
    return x

def update_w(w, grad, learning_rate):
    """Update weight using gradient descent."""
    return w - learning_rate * grad

# ----------------------------------------------------------------------------
# 2. Data and Parameters Setup
# ----------------------------------------------------------------------------

x1 = 0.1
x2 = 0.4
target = 0.7
learning_rate = 0.01

# Initialize weights randomly
w1 = numpy.random.rand()
w2 = numpy.random.rand()

print("Initial weights: w1 =", w1, ", w2 =", w2)

# ----------------------------------------------------------------------------
# 3. Training Loop
# ----------------------------------------------------------------------------

predicted_output = []
network_error = []

for k in range(80000):
    # 3.1 Forward Pass
    y = w1 * x1 + w2 * x2
    predicted = sigmoid(y)
    err = error(predicted, target)
    predicted_output.append(predicted)
    network_error.append(err)

    # 3.2 Backward Pass (Gradient Calculation)
    g1 = error_predicted_deriv(predicted, target)  # dE/dpred
    g2 = sigmoid_sop_deriv(y)                      # dpred/dsop
    g3w1 = sop_w_deriv(x1)                         # dsop/dw1
    g3w2 = sop_w_deriv(x2)                         # dsop/dw2
    gradw1 = g3w1 * g2 * g1                        # dE/dw1
    gradw2 = g3w2 * g2 * g1                        # dE/dw2

    # 3.3 Update Weights
    w1 = update_w(w1, gradw1, learning_rate)
    w2 = update_w(w2, gradw2, learning_rate)

# ----------------------------------------------------------------------------
# 4. Plotting Results
# ----------------------------------------------------------------------------

plt.figure()
plt.plot(network_error)
plt.title("Iteration Number vs Error")
plt.xlabel("Iteration Number")
plt.ylabel("Error")
plt.show()

plt.figure()
plt.plot(predicted_output)
plt.title("Iteration Number vs Prediction")
plt.xlabel("Iteration Number")
plt.ylabel("Prediction")
plt.show()
